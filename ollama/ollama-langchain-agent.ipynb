{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ LangChain å®ç°æœ¬åœ° Agent\n",
    "\n",
    "## ç®€ä»‹\n",
    "\n",
    "ReActï¼ˆReasoning and Actingï¼‰æ˜¯ä¸€ç§å°†æ¨ç†ä¸è¡ŒåŠ¨ç›¸ç»“åˆçš„æ¡†æ¶ï¼Œç”¨äºå¢å¼ºæ™ºèƒ½ä½“åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†é€»è¾‘æ¨ç†ä¸å®é™…è¡ŒåŠ¨ç´§å¯†ç»“åˆï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­æ›´æœ‰æ•ˆåœ°å®Œæˆä»»åŠ¡ã€‚\n",
    "\n",
    "\n",
    "![](https://datawhalechina.github.io/handy-ollama/images/C7-5-1.png)\n",
    "\n",
    "\n",
    "æœ¬æ–‡æ¡£ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ ReAct æ¡†æ¶åœ¨ Ollama ä¸­å®ç°æœ¬åœ°ä»£ç†ï¼ˆAgentï¼‰ã€‚é€šè¿‡ç»“åˆ Ollama çš„åŠŸèƒ½ä¸ ReAct çš„çµæ´»æ€§ï¼Œç”¨æˆ·èƒ½å¤Ÿåœ¨æœ¬åœ°ç¯å¢ƒä¸­åˆ›å»ºä¸€ä¸ªé«˜æ•ˆçš„äº¤äº’å¼ä»£ç†ã€‚æ­¤å®ç°èƒ½å¤Ÿå¤„ç†å¤æ‚ä»»åŠ¡ï¼Œæ”¯æŒå¤šç§äº¤äº’æ¨¡å¼ï¼Œå¹¶ä¸”ä¼˜åŒ–äº†ä»»åŠ¡è‡ªåŠ¨åŒ–å’Œç”¨æˆ·ä½“éªŒï¼Œé€‚åˆéœ€è¦é«˜å®æ—¶æ€§çš„æœ¬åœ°åº”ç”¨åœºæ™¯ã€‚\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¯¼å…¥ä¾èµ–\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool  \n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import render_text_description\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆå§‹åŒ– Agent å·¥å…·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰ SearchInput ç±»ç»§æ‰¿ BaseModelï¼Œç”¨äºå®šä¹‰è¾“å…¥æ•°æ®çš„æ¨¡å¼ã€‚\n",
    "\n",
    "@tool(args_schema=SearchInput) ä½¿ç”¨å·¥å…·è£…é¥°å™¨è£…é¥° weather_forecast å‡½æ•°ï¼Œå¹¶æŒ‡å®šå…¶è¾“å…¥æ¨¡å¼ä¸º SearchInputã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather for \n",
      "weather_forecast   ä¸‹å¤§é›¨.\n",
      "current_datetime Saturday 22 March 2025, 08:51PM\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# è‡ªå®šä¹‰å·¥å…·\n",
    "# ============================================================\n",
    "import datetime\n",
    "\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    location: str = Field(description=\"Weather for location\")  # å®šä¹‰ä¸€ä¸ª Pydantic æ¨¡å‹ï¼Œç”¨äºæè¿°è¾“å…¥æ¨¡å¼ï¼Œå¹¶æä¾›æè¿°ä¿¡æ¯\n",
    "\n",
    "@tool(args_schema=SearchInput)\n",
    "def weather_forecast(location: str):\n",
    "    \"\"\"Weather for location to search for\"\"\"\n",
    "    print(f\"Weather for {location}\")  # æ‰“å°è¦é¢„æŠ¥å¤©æ°”çš„ä½ç½®\n",
    "    # return f\"A dummy forecast for {location}.\"  # è¿”å›ç»™å®šä½ç½®çš„è™šæ‹Ÿå¤©æ°”é¢„æŠ¥\n",
    "    return f\" {location} ä¸‹å¤§é›¨.\"  # è¿”å›ç»™å®šä½ç½®çš„è™šæ‹Ÿå¤©æ°”é¢„æŠ¥\n",
    "\n",
    "\n",
    "@tool\n",
    "def current_datetime(input: str) -> str:  # Note: A tool always needs an input and returns an output\n",
    "    \"\"\"Get the current date and time\n",
    "\n",
    "    Returns:\n",
    "        str: The current date and time\n",
    "    \"\"\"\n",
    "    current_time = datetime.datetime.now()\n",
    "    formatted_time = current_time.strftime('%A %d %B %Y, %I:%M%p')\n",
    "    return formatted_time\n",
    "\n",
    "print(\"weather_forecast\", weather_forecast(''))\n",
    "print(\"current_datetime\", current_datetime(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æœ¬åœ°è¿è¡Œ\n",
    "\n",
    "åœ¨æœ¬ä¾‹ä¸­ä½¿ç”¨ gemma:2b æ¨¡å‹ï¼Œå¯¹äºä¸åŒç±»å‹çš„æ¨¡å‹ï¼Œè¾“å‡ºç»“æœå¯èƒ½ä¼šå¾ˆä¸ä¸€æ ·ï¼ˆéšæœºæ€§æ¯”è¾ƒå¤§ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not have access to real-time information, including weather updates. \\n\\nTo get the current weather in Paris, I recommend checking a reliable weather website or app such as:\\n\\n* **Google Weather:** Just search \"weather in Paris\" on Google.\\n* **AccuWeather:** https://www.accuweather.com/\\n* **The Weather Channel:** https://weather.com/ \\n\\n\\nHave a wonderful time in Paris!  ğŸ˜Š\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æµ‹è¯•ä¸åŠ å·¥å…·\n",
    "llm = ChatOllama(model=\"gemma2:2b\")  # åˆå§‹åŒ– ChatOllama æ¨¡å‹ï¼Œä½¿ç”¨ \"gemma2:2b\"\n",
    "llm.invoke(\"What is the weather in Paris?\").content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hwchase17/react-json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwchase17_react_json_prompt ='''\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "The way you use the tools is by specifying a json blob.\n",
    "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
    "\n",
    "The only values that should be in the \"action\" field are: {tool_names}\n",
    "\n",
    "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
    "\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "'''\n",
    "\n",
    "template = \"\"\" \n",
    "You are a great AI-Assistant that has access to additional tools in order to answer the following questions as best you can. Always answer in the same language as the user question. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "To use a tool, please use the following format:\n",
    "\n",
    "'''\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat 3 times)\n",
    "'''\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "'''\n",
    "Thought: Do I need to use a tool? No\n",
    "Final Answer: [your response here]\n",
    "'''\n",
    "\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "# æµ‹è¯•ä½¿ç”¨å·¥å…·\n",
    "# llm = ChatOllama(model=\"gemma2:2b\")  # åˆå§‹åŒ– ChatOllama æ¨¡å‹ï¼Œä½¿ç”¨ \"gemma2:2b\"\n",
    "llm = ChatOllama(model=\"llama3.2\")  # åˆå§‹åŒ– ChatOllama æ¨¡å‹ï¼Œä½¿ç”¨ \"llama3.2\"\n",
    "tools = [weather_forecast, current_datetime]  # ä½¿ç”¨ weather_forecast å·¥å…·\n",
    "# prompt = hub.pull(\"hwchase17/react-json\")  # ä» hub æ‹‰å–ç‰¹å®šæç¤º\n",
    "# prompt = PromptTemplate.from_template(hwchase17_react_json_prompt)\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# prompt = prompt.partial(\n",
    "#     tools=render_text_description(tools),  # ä¸ºæç¤ºå‘ˆç°å·¥å…·çš„æ–‡æœ¬æè¿°\n",
    "#     tool_names=\", \".join([t.name for t in tools]),  # å°†å·¥å…·åç§°è¿æ¥æˆä¸€ä¸ªä»¥é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²\n",
    "# )\n",
    "\n",
    "# print(\"tools\", render_text_description(tools))\n",
    "# print(\"tool_names\", \", \".join([t.name for t in tools]))\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)  # ä½¿ç”¨ llmã€å·¥å…·å’Œè‡ªå®šä¹‰æç¤ºåˆ›å»ºä»£ç†\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, verbose=True)  # ä½¿ç”¨æŒ‡å®šå‚æ•°åˆå§‹åŒ– AgentExecutor\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: current_datetime\n",
      "Action Input: \u001b[0m\u001b[33;1m\u001b[1;3mSaturday 22 March 2025, 08:51PM\u001b[0m\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: I am functioning within normal parameters and ready to assist you.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I am functioning within normal parameters and ready to assist you.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_prompt = \"How are you?\"\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": user_prompt}\n",
    ")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: current_datetime\n",
      "Action Input: \u001b[0m\u001b[33;1m\u001b[1;3mSaturday 22 March 2025, 08:51PM\u001b[0m\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: Saturday 22 March 2025, 08:51PM\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Saturday 22 March 2025, 08:51PM\n"
     ]
    }
   ],
   "source": [
    "user_prompt=\"Get the current date and time?\"\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": user_prompt}\n",
    ")\n",
    "print(response[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: weather_forecast\n",
      "Action Input: New York\u001b[0mWeather for New York\n",
      "\u001b[36;1m\u001b[1;3m New York ä¸‹å¤§é›¨.\u001b[0m\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: The current weather in New York is experiencing heavy rain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The current weather in New York is experiencing heavy rain.\n"
     ]
    }
   ],
   "source": [
    "user_prompt=\"What is the weather in New York?\"\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": user_prompt}\n",
    ")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨å¯¹è¯å†å²\n",
    "\n",
    "åœ¨ä½¿ç”¨å¯¹è¯å†å²æ—¶ï¼Œéœ€è¦ä½¿ç”¨ react-chat Prompt æ¨¡æ¿ã€‚åœ¨ invoke æ—¶ï¼ŒåŠ å…¥ chat_historyã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather for Your Location\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name? Only use a tool if needed, otherwise respond with Final Answer\",\n",
       " 'chat_history': 'Human: Hi! My name is Bob\\nAI: Hello Bob! Nice to meet you',\n",
       " 'output': 'Nice to meet you too, Bob! How can I help you today? \\n```'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ‹‰å»ç‰¹å®šæç¤ºï¼Œæ³¨æ„æ­¤å¤„ä½¿ç”¨çš„æ˜¯ react-chat\n",
    "prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "\n",
    "# æ„å»º ReAct agent\n",
    "agent_history = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent_history, tools=tools, verbose=False)\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"what's my name? Only use a tool if needed, otherwise respond with Final Answer\",\n",
    "        \"chat_history\": \"Human: Hi! My name is Bob\\nAI: Hello Bob! Nice to meet you\",\n",
    "    }\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
