{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 LangChain 实现本地 Agent\n",
    "\n",
    "## 简介\n",
    "\n",
    "ReAct（Reasoning and Acting）是一种将推理与行动相结合的框架，用于增强智能体在复杂任务中的表现。该框架通过将逻辑推理与实际行动紧密结合，使智能体能够在动态环境中更有效地完成任务。\n",
    "\n",
    "\n",
    "![](https://datawhalechina.github.io/handy-ollama/images/C7-5-1.png)\n",
    "\n",
    "\n",
    "本文档介绍了如何使用 ReAct 框架在 Ollama 中实现本地代理（Agent）。通过结合 Ollama 的功能与 ReAct 的灵活性，用户能够在本地环境中创建一个高效的交互式代理。此实现能够处理复杂任务，支持多种交互模式，并且优化了任务自动化和用户体验，适合需要高实时性的本地应用场景。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入依赖\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool  \n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import render_text_description\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化 Agent 工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 SearchInput 类继承 BaseModel，用于定义输入数据的模式。\n",
    "\n",
    "@tool(args_schema=SearchInput) 使用工具装饰器装饰 weather_forecast 函数，并指定其输入模式为 SearchInput。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather for \n",
      "weather_forecast   下大雨.\n",
      "current_datetime Saturday 22 March 2025, 08:51PM\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 自定义工具\n",
    "# ============================================================\n",
    "import datetime\n",
    "\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    location: str = Field(description=\"Weather for location\")  # 定义一个 Pydantic 模型，用于描述输入模式，并提供描述信息\n",
    "\n",
    "@tool(args_schema=SearchInput)\n",
    "def weather_forecast(location: str):\n",
    "    \"\"\"Weather for location to search for\"\"\"\n",
    "    print(f\"Weather for {location}\")  # 打印要预报天气的位置\n",
    "    # return f\"A dummy forecast for {location}.\"  # 返回给定位置的虚拟天气预报\n",
    "    return f\" {location} 下大雨.\"  # 返回给定位置的虚拟天气预报\n",
    "\n",
    "\n",
    "@tool\n",
    "def current_datetime(input: str) -> str:  # Note: A tool always needs an input and returns an output\n",
    "    \"\"\"Get the current date and time\n",
    "\n",
    "    Returns:\n",
    "        str: The current date and time\n",
    "    \"\"\"\n",
    "    current_time = datetime.datetime.now()\n",
    "    formatted_time = current_time.strftime('%A %d %B %Y, %I:%M%p')\n",
    "    return formatted_time\n",
    "\n",
    "print(\"weather_forecast\", weather_forecast(''))\n",
    "print(\"current_datetime\", current_datetime(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本地运行\n",
    "\n",
    "在本例中使用 gemma:2b 模型，对于不同类型的模型，输出结果可能会很不一样（随机性比较大）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not have access to real-time information, including weather updates. \\n\\nTo get the current weather in Paris, I recommend checking a reliable weather website or app such as:\\n\\n* **Google Weather:** Just search \"weather in Paris\" on Google.\\n* **AccuWeather:** https://www.accuweather.com/\\n* **The Weather Channel:** https://weather.com/ \\n\\n\\nHave a wonderful time in Paris!  😊\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试不加工具\n",
    "llm = ChatOllama(model=\"gemma2:2b\")  # 初始化 ChatOllama 模型，使用 \"gemma2:2b\"\n",
    "llm.invoke(\"What is the weather in Paris?\").content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hwchase17/react-json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwchase17_react_json_prompt ='''\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "The way you use the tools is by specifying a json blob.\n",
    "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
    "\n",
    "The only values that should be in the \"action\" field are: {tool_names}\n",
    "\n",
    "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
    "\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "'''\n",
    "\n",
    "template = \"\"\" \n",
    "You are a great AI-Assistant that has access to additional tools in order to answer the following questions as best you can. Always answer in the same language as the user question. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "To use a tool, please use the following format:\n",
    "\n",
    "'''\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat 3 times)\n",
    "'''\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "'''\n",
    "Thought: Do I need to use a tool? No\n",
    "Final Answer: [your response here]\n",
    "'''\n",
    "\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "# 测试使用工具\n",
    "# llm = ChatOllama(model=\"gemma2:2b\")  # 初始化 ChatOllama 模型，使用 \"gemma2:2b\"\n",
    "llm = ChatOllama(model=\"llama3.2\")  # 初始化 ChatOllama 模型，使用 \"llama3.2\"\n",
    "tools = [weather_forecast, current_datetime]  # 使用 weather_forecast 工具\n",
    "# prompt = hub.pull(\"hwchase17/react-json\")  # 从 hub 拉取特定提示\n",
    "# prompt = PromptTemplate.from_template(hwchase17_react_json_prompt)\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# prompt = prompt.partial(\n",
    "#     tools=render_text_description(tools),  # 为提示呈现工具的文本描述\n",
    "#     tool_names=\", \".join([t.name for t in tools]),  # 将工具名称连接成一个以逗号分隔的字符串\n",
    "# )\n",
    "\n",
    "# print(\"tools\", render_text_description(tools))\n",
    "# print(\"tool_names\", \", \".join([t.name for t in tools]))\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)  # 使用 llm、工具和自定义提示创建代理\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, verbose=True)  # 使用指定参数初始化 AgentExecutor\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: current_datetime\n",
      "Action Input: \u001b[0m\u001b[33;1m\u001b[1;3mSaturday 22 March 2025, 08:51PM\u001b[0m\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: I am functioning within normal parameters and ready to assist you.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I am functioning within normal parameters and ready to assist you.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_prompt = \"How are you?\"\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": user_prompt}\n",
    ")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: current_datetime\n",
      "Action Input: \u001b[0m\u001b[33;1m\u001b[1;3mSaturday 22 March 2025, 08:51PM\u001b[0m\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: Saturday 22 March 2025, 08:51PM\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Saturday 22 March 2025, 08:51PM\n"
     ]
    }
   ],
   "source": [
    "user_prompt=\"Get the current date and time?\"\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": user_prompt}\n",
    ")\n",
    "print(response[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: weather_forecast\n",
      "Action Input: New York\u001b[0mWeather for New York\n",
      "\u001b[36;1m\u001b[1;3m New York 下大雨.\u001b[0m\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: The current weather in New York is experiencing heavy rain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The current weather in New York is experiencing heavy rain.\n"
     ]
    }
   ],
   "source": [
    "user_prompt=\"What is the weather in New York?\"\n",
    "response = agent_executor.invoke(\n",
    "    {\"input\": user_prompt}\n",
    ")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用对话历史\n",
    "\n",
    "在使用对话历史时，需要使用 react-chat Prompt 模板。在 invoke 时，加入 chat_history。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather for Your Location\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name? Only use a tool if needed, otherwise respond with Final Answer\",\n",
       " 'chat_history': 'Human: Hi! My name is Bob\\nAI: Hello Bob! Nice to meet you',\n",
       " 'output': 'Nice to meet you too, Bob! How can I help you today? \\n```'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拉去特定提示，注意此处使用的是 react-chat\n",
    "prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "\n",
    "# 构建 ReAct agent\n",
    "agent_history = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent_history, tools=tools, verbose=False)\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"what's my name? Only use a tool if needed, otherwise respond with Final Answer\",\n",
    "        \"chat_history\": \"Human: Hi! My name is Bob\\nAI: Hello Bob! Nice to meet you\",\n",
    "    }\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
