# llama.cpp/example/tts

https://github.com/ggml-org/llama.cpp/blob/master/examples/tts/README.md

## 下载 TTS 模型

```bash
git clone --branch main --single-branch --depth 1 https://huggingface.co/OuteAI/OuteTTS-0.2-500M
cd OuteTTS-0.2-500M
git lfs install
git lfs pull
```


## Convert the model to .gguf format

```
conda activate llm-study
pip install sentencepiece
python convert_hf_to_gguf.py /Users/tiankonguse-m3/models/OuteTTS-0.2-500M/ --outfile models/outetts-0.2-0.5B-f16.gguf --outtype f16
```


## [可选]量化参数调整

```
build/bin/llama-quantize models/outetts-0.2-0.5B-f16.gguf models/outetts-0.2-0.5B-q8_0.gguf q8_0
```

## 下载 voice decoder 模型

这个模型使用 git 拉取会卡主，所以使用 huggingface-cli 下载。  

```
huggingface-cli download  novateur/WavTokenizer-large-speech-75token --local-dir WavTokenizer-large-speech-75token 
```

模型由 PyTorch checkpoint (.ckpt) 转化为 huggingface format  

```
python examples/tts/convert_pt_to_hf.py /Users/tiankonguse-m3/models/WavTokenizer-large-speech-75token/wavtokenizer_large_speech_320_v2.ckpt

# Total size:   255.91 MB
# Model has been successfully converted and saved to /Users/tiankonguse-m3/models/WavTokenizer-large-speech-75token/model.safetensors
# Metadata has been saved to /Users/tiankonguse-m3/models/WavTokenizer-large-speech-75token/index.json
# Config has been saved to /Users/tiankonguse-m3/models/WavTokenizer-large-speech-75tokenconfig.json
```


convert the huggingface format to gguf


```
python convert_hf_to_gguf.py  /Users/tiankonguse-m3/models/WavTokenizer-large-speech-75token/ --outfile /Users/tiankonguse-m3/models/wavtokenizer-large-75-f16.gguf --outtype f16
```


## Running the example

```
build/bin/llama-tts  -m  /Users/tiankonguse-m3/models/outetts-0.2-0.5B-f16.gguf -mv /Users/tiankonguse-m3/models/wavtokenizer-large-75-f16.gguf -p  "Hello world"
```